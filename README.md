# Sampling Assignment

## Objective
To analyze the effect of different sampling techniques on machine learning
models when working with an imbalanced credit card dataset.

## Dataset
Credit Card Fraud Detection dataset  
Source: GitHub

## Sampling Techniques Used
1. Random Under Sampling
2. Random Over Sampling
3. SMOTE
4. NearMiss
5. SMOTEENN

## Machine Learning Models
- Logistic Regression
- Decision Tree
- Random Forest
- Support Vector Machine
- Naive Bayes

## Results
An accuracy comparison table was generated for each combination of
sampling technique and model.

## Observations
- SMOTE performed best with ensemble models.
- Under-sampling led to loss of information.
- Random Forest was most stable across techniques.

## Conclusion
Sampling techniques significantly affect model performance in imbalanced
datasets. Choosing the correct strategy is model-dependent.
